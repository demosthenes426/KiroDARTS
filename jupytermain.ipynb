{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7f61d7",
   "metadata": {},
   "source": [
    "# DARTS Stock Forecasting System - Main Execution Script\n",
    "\n",
    "This script implements a comprehensive time series forecasting pipeline using DARTS\n",
    "neural network models to predict stock prices 5 business days into the future.\n",
    "\n",
    "The script is structured like a Jupyter notebook with standardized cell division\n",
    "comments for easy experimentation and development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba195c91",
   "metadata": {},
   "source": [
    "# # DARTS Stock Forecasting System\n",
    "\n",
    " This notebook implements a comprehensive time series forecasting pipeline that:\n",
    " - Processes multi-variate stock data with custom business day handling\n",
    " - Tests multiple DARTS neural network models\n",
    " - Provides comprehensive evaluation and visualization\n",
    " - Saves model artifacts for future predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019ca876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "user = 'demosthenes426'\n",
    "# Replace 'YOUR_STAND_IN_GITHUB_TOKEN_HERE' with your actual Personal Access Token\n",
    "stand_in_token = ''\n",
    "branch_name = 'main'  # Replace with the name of the branch you want to clone\n",
    "\n",
    "os.environ['GITHUB_TOKEN'] = stand_in_token\n",
    "\n",
    "!git clone --branch {branch_name} https://{os.environ['GITHUB_TOKEN']}@github.com/{user}/KiroDARTS.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install darts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2209ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Import Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import logging\n",
    "import argparse\n",
    "import sys\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "from datetime import datetime, timedelta\n",
    "from darts import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e212010",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e3258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom component imports\n",
    "from src.data_loader import DataLoader\n",
    "from src.data_preprocessor import DataPreprocessor\n",
    "from src.custom_holiday_calendar import CustomHolidayCalendar\n",
    "from src.darts_timeseries_creator import DartsTimeSeriesCreator\n",
    "from src.data_splitter import DataSplitter\n",
    "from src.data_scaler import DataScaler\n",
    "from src.target_creator import TargetCreator\n",
    "from src.model_factory import ModelFactory\n",
    "from src.model_trainer import ModelTrainer\n",
    "from src.model_evaluator import ModelEvaluator\n",
    "from src.results_visualizer import ResultsVisualizer\n",
    "from src.model_artifact_saver import ModelArtifactSaver\n",
    "from src.data_integrity_validator import DataIntegrityValidator\n",
    "\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a2fdf7",
   "metadata": {},
   "source": [
    "# # Configuration and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7357f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Global Configuration\n",
    "\n",
    "def setup_logging(log_level: str = \"INFO\") -> logging.Logger:\n",
    "    \"\"\"Setup logging configuration.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=getattr(logging, log_level.upper()),\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.StreamHandler(sys.stdout),\n",
    "            logging.FileHandler('darts_forecasting.log')\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "def setup_directories() -> Dict[str, Path]:\n",
    "    \"\"\"Setup output directories.\"\"\"\n",
    "    paths = {\n",
    "        'data': Path(\"Data/covariaterawdata1.csv\"),\n",
    "        'output': Path(\"output\"),\n",
    "        'models': Path(\"output/models\"),\n",
    "        'plots': Path(\"output/plots\"),\n",
    "        'artifacts': Path(\"model_artifacts\")\n",
    "    }\n",
    "    \n",
    "    # Create output directories\n",
    "    for key, path in paths.items():\n",
    "        if key != 'data':  # Don't create data file\n",
    "            path.mkdir(exist_ok=True)\n",
    "    \n",
    "    return paths\n",
    "\n",
    "# Global configuration constants\n",
    "CONFIG = {\n",
    "    'prediction_horizon': 5,  # 5-day future prediction\n",
    "    'train_ratio': 0.7,\n",
    "    'val_ratio': 0.15,\n",
    "    'test_ratio': 0.15,\n",
    "    'epochs': 100,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'early_stopping_patience': 10,\n",
    "    'input_chunk_length': 30,\n",
    "    'output_chunk_length': 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5652db",
   "metadata": {},
   "source": [
    "# # Main Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a5eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Pipeline Implementation\n",
    "\n",
    "def load_and_preprocess_data(data_path: Path, logger: logging.Logger) -> pd.DataFrame:\n",
    "    \"\"\"Load and preprocess raw stock data.\"\"\"\n",
    "    logger.info(\"=== Data Loading and Preprocessing Phase ===\")\n",
    "    \n",
    "    try:\n",
    "        # Load raw data\n",
    "        logger.info(f\"Loading data from {data_path}\")\n",
    "        data_loader = DataLoader()\n",
    "        raw_df = data_loader.load_data(str(data_path))\n",
    "        logger.info(f\"Loaded {len(raw_df)} rows of data\")\n",
    "        \n",
    "        # Preprocess data\n",
    "        logger.info(\"Preprocessing data...\")\n",
    "        preprocessor = DataPreprocessor()\n",
    "        processed_df = preprocessor.preprocess_data(raw_df)\n",
    "        logger.info(f\"Preprocessed data shape: {processed_df.shape}\")\n",
    "        \n",
    "        return processed_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in data loading/preprocessing: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timeseries_with_calendar(df: pd.DataFrame, logger: logging.Logger) -> Tuple[TimeSeries, Any]:\n",
    "    \"\"\"Create DARTS TimeSeries with custom holiday calendar.\"\"\"\n",
    "    logger.info(\"=== Custom Holiday Calendar and TimeSeries Creation Phase ===\")\n",
    "    \n",
    "    try:\n",
    "        # Create custom holiday calendar (for reference)\n",
    "        logger.info(\"Creating custom holiday calendar...\")\n",
    "        calendar_creator = CustomHolidayCalendar()\n",
    "        custom_freq, holidays = calendar_creator.create_custom_calendar(df)\n",
    "        logger.info(f\"Created custom calendar with {len(holidays)} holidays\")\n",
    "        \n",
    "        # Create DARTS TimeSeries (uses data-driven holiday discovery internally)\n",
    "        logger.info(\"Converting to DARTS TimeSeries...\")\n",
    "        ts_creator = DartsTimeSeriesCreator()\n",
    "        timeseries = ts_creator.create_timeseries(df)\n",
    "        logger.info(f\"Created TimeSeries with {len(timeseries)} points\")\n",
    "        \n",
    "        return timeseries, custom_freq\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in TimeSeries creation: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07695d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_scale_data(timeseries: TimeSeries, config: Dict, logger: logging.Logger) -> Tuple[TimeSeries, TimeSeries, TimeSeries, Any]:\n",
    "    \"\"\"Split and scale the TimeSeries data.\"\"\"\n",
    "    logger.info(\"=== Data Splitting and Scaling Phase ===\")\n",
    "    \n",
    "    try:\n",
    "        # Split data temporally (uses fixed 70/15/15 ratios)\n",
    "        logger.info(\"Splitting data temporally...\")\n",
    "        splitter = DataSplitter()\n",
    "        train_ts, val_ts, test_ts = splitter.split_data(timeseries)\n",
    "        logger.info(f\"Split sizes - Train: {len(train_ts)}, Val: {len(val_ts)}, Test: {len(test_ts)}\")\n",
    "        \n",
    "        # Scale features\n",
    "        logger.info(\"Scaling features...\")\n",
    "        scaler = DataScaler()\n",
    "        scaled_train, scaled_val, scaled_test, fitted_scaler = scaler.scale_data(train_ts, val_ts, test_ts)\n",
    "        logger.info(\"Data scaling completed\")\n",
    "        \n",
    "        return scaled_train, scaled_val, scaled_test, fitted_scaler\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in data splitting/scaling: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09c7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_targets(timeseries: TimeSeries, config: Dict, logger: logging.Logger) -> TimeSeries:\n",
    "    \"\"\"Create target variables for prediction.\"\"\"\n",
    "    logger.info(\"=== Target Creation Phase ===\")\n",
    "    \n",
    "    try:\n",
    "        target_creator = TargetCreator(config['prediction_horizon'])\n",
    "        # Use column index 0 for adjusted_close (first column after preprocessing)\n",
    "        targets = target_creator.create_targets(timeseries, \"0\")\n",
    "        logger.info(f\"Created targets with {len(targets)} points\")\n",
    "        return targets\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in target creation: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835cefc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_models(train_ts: TimeSeries, val_ts: TimeSeries, config: Dict, logger: logging.Logger) -> Dict[str, Any]:\n",
    "    \"\"\"Train all available DARTS models.\"\"\"\n",
    "    logger.info(\"=== Model Factory and Training Phase ===\")\n",
    "    \n",
    "    try:\n",
    "        # Create models\n",
    "        logger.info(\"Creating model instances...\")\n",
    "        model_factory = ModelFactory()\n",
    "        models = model_factory.create_models()\n",
    "        logger.info(f\"Created {len(models)} models: {list(models.keys())}\")\n",
    "        \n",
    "        # Train models\n",
    "        logger.info(\"Training models...\")\n",
    "        trainer = ModelTrainer()\n",
    "        training_results = {}\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            logger.info(f\"Training {model_name}...\")\n",
    "            try:\n",
    "                result = trainer.train_model(model, train_ts, val_ts)\n",
    "                training_results[model_name] = {\n",
    "                    'model': model,\n",
    "                    'results': result\n",
    "                }\n",
    "                logger.info(f\"{model_name} training completed - Final loss: {result.final_val_loss:.4f}\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to train {model_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        logger.info(f\"Successfully trained {len(training_results)} models\")\n",
    "        return training_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in model training: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14d85b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_visualize(training_results: Dict, test_ts: TimeSeries, paths: Dict[str, Path], logger: logging.Logger) -> Dict[str, Any]:\n",
    "    \"\"\"Evaluate models and create visualizations.\"\"\"\n",
    "    logger.info(\"=== Model Evaluation and Visualization Phase ===\")\n",
    "    \n",
    "    try:\n",
    "        evaluator = ModelEvaluator()\n",
    "        visualizer = ResultsVisualizer()\n",
    "        evaluation_results = {}\n",
    "        \n",
    "        # Evaluate each model\n",
    "        for model_name, model_data in training_results.items():\n",
    "            logger.info(f\"Evaluating {model_name}...\")\n",
    "            try:\n",
    "                eval_result = evaluator.evaluate_model(model_data['model'], test_ts)\n",
    "                evaluation_results[model_name] = eval_result\n",
    "                logger.info(f\"{model_name} - MAE: {eval_result.mae:.4f}, RMSE: {eval_result.rmse:.4f}\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to evaluate {model_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Create visualizations\n",
    "        logger.info(\"Creating visualizations...\")\n",
    "        visualizer.visualize_results(evaluation_results, str(paths['plots']))\n",
    "        logger.info(\"Visualizations saved\")\n",
    "        \n",
    "        return evaluation_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in evaluation/visualization: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a086f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_artifacts(training_results: Dict, scaler: Any, paths: Dict[str, Path], logger: logging.Logger):\n",
    "    \"\"\"Save model artifacts for future use.\"\"\"\n",
    "    logger.info(\"=== Model Artifact Management Phase ===\")\n",
    "    \n",
    "    try:\n",
    "        artifact_saver = ModelArtifactSaver()\n",
    "        \n",
    "        for model_name, model_data in training_results.items():\n",
    "            logger.info(f\"Saving artifacts for {model_name}...\")\n",
    "            try:\n",
    "                metadata = {\n",
    "                    'model_name': model_name,\n",
    "                    'training_results': model_data['results'].__dict__,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                artifact_path = artifact_saver.save_artifacts(\n",
    "                    model_data['model'], \n",
    "                    scaler, \n",
    "                    metadata,\n",
    "                    str(paths['artifacts'])\n",
    "                )\n",
    "                logger.info(f\"Saved {model_name} artifacts to {artifact_path}\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to save artifacts for {model_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in artifact saving: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f30388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data_integrity(timeseries: TimeSeries, scaler: Any, logger: logging.Logger):\n",
    "    \"\"\"Run comprehensive data integrity validation.\"\"\"\n",
    "    logger.info(\"=== Data Integrity Validation Phase ===\")\n",
    "    \n",
    "    try:\n",
    "        validator = DataIntegrityValidator()\n",
    "        validation_report = validator.validate_data_integrity(timeseries, scaler)\n",
    "        \n",
    "        if validation_report.data_integrity_passed:\n",
    "            logger.info(\"✓ Data integrity validation PASSED\")\n",
    "        else:\n",
    "            logger.warning(\"✗ Data integrity validation FAILED\")\n",
    "            for issue in validation_report.issues:\n",
    "                logger.warning(f\"  Issue: {issue}\")\n",
    "        \n",
    "        for warning in validation_report.warnings:\n",
    "            logger.warning(f\"  Warning: {warning}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in data integrity validation: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d215110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_report(training_results: Dict, evaluation_results: Dict, logger: logging.Logger):\n",
    "    \"\"\"Generate final performance report.\"\"\"\n",
    "    logger.info(\"=== Final Results and Summary Phase ===\")\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"DARTS Stock Forecasting Pipeline Complete!\")\n",
    "        logger.info(\"=\" * 60)\n",
    "        logger.info(\"FINAL PERFORMANCE SUMMARY\")\n",
    "        logger.info(\"=\" * 60)\n",
    "        \n",
    "        # Sort models by performance (MAE)\n",
    "        sorted_results = sorted(\n",
    "            evaluation_results.items(), \n",
    "            key=lambda x: x[1].mae\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Model Performance Ranking (by MAE):\")\n",
    "        for i, (model_name, result) in enumerate(sorted_results, 1):\n",
    "            logger.info(f\"{i:2d}. {model_name:15s} - MAE: {result.mae:.4f}, RMSE: {result.rmse:.4f}, MAPE: {result.mape:.2f}%\")\n",
    "        \n",
    "        # Training convergence summary\n",
    "        logger.info(\"\\nTraining Convergence Summary:\")\n",
    "        for model_name, model_data in training_results.items():\n",
    "            result = model_data['results']\n",
    "            status = \"✓ Converged\" if result.convergence_achieved else \"✗ No convergence\"\n",
    "            logger.info(f\"{model_name:15s} - {status}, Final Val Loss: {result.final_val_loss:.4f}\")\n",
    "        \n",
    "        logger.info(\"\\nCheck output directories for:\")\n",
    "        logger.info(\"- Saved models and artifacts: model_artifacts/\")\n",
    "        logger.info(\"- Visualization plots: output/plots/\")\n",
    "        logger.info(\"- Training logs: darts_forecasting.log\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating final report: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f99ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_pipeline(data_path: str, log_level: str = \"INFO\", models_subset: Optional[List[str]] = None) -> bool:\n",
    "    \"\"\"\n",
    "    Run the complete DARTS forecasting pipeline.\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to the CSV data file\n",
    "        log_level: Logging level (DEBUG, INFO, WARNING, ERROR)\n",
    "        models_subset: Optional list of specific models to train\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if pipeline completed successfully\n",
    "    \"\"\"\n",
    "    # Setup\n",
    "    logger = setup_logging(log_level)\n",
    "    paths = setup_directories()\n",
    "    \n",
    "    # Override data path if provided\n",
    "    if data_path:\n",
    "        paths['data'] = Path(data_path)\n",
    "    \n",
    "    logger.info(\"Starting DARTS Stock Forecasting System...\")\n",
    "    logger.info(f\"Data path: {paths['data']}\")\n",
    "    logger.info(f\"DARTS available: {DARTS_AVAILABLE}\")\n",
    "    \n",
    "    if not DARTS_AVAILABLE:\n",
    "        logger.error(\"DARTS library not available. Please install DARTS to run the pipeline.\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # 1. Load and preprocess data\n",
    "        processed_df = load_and_preprocess_data(paths['data'], logger)\n",
    "        \n",
    "        # 2. Create TimeSeries with custom calendar\n",
    "        timeseries, custom_freq = create_timeseries_with_calendar(processed_df, logger)\n",
    "        \n",
    "        # 3. Split and scale data\n",
    "        train_ts, val_ts, test_ts, scaler = split_and_scale_data(timeseries, CONFIG, logger)\n",
    "        \n",
    "        # 4. Create targets (for validation purposes)\n",
    "        targets = create_targets(timeseries, CONFIG, logger)\n",
    "        \n",
    "        # 5. Train models\n",
    "        training_results = train_all_models(train_ts, val_ts, CONFIG, logger)\n",
    "        \n",
    "        if not training_results:\n",
    "            logger.error(\"No models were successfully trained. Pipeline failed.\")\n",
    "            return False\n",
    "        \n",
    "        # 6. Evaluate and visualize\n",
    "        evaluation_results = evaluate_and_visualize(training_results, test_ts, paths, logger)\n",
    "        \n",
    "        # 7. Save artifacts\n",
    "        save_artifacts(training_results, scaler, paths, logger)\n",
    "        \n",
    "        # 8. Validate data integrity\n",
    "        validate_data_integrity(timeseries, scaler, logger)\n",
    "        \n",
    "        # 9. Generate final report\n",
    "        generate_final_report(training_results, evaluation_results, logger)\n",
    "        \n",
    "        logger.info(\"Pipeline completed successfully!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Pipeline failed with error: {e}\")\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0880c",
   "metadata": {
    "vscode": {
     "languageId": "coffeescript"
    }
   },
   "outputs": [],
   "source": [
    "def run_quick_test(data_path: str, log_level: str = \"INFO\") -> bool:\n",
    "    \"\"\"\n",
    "    Run a quick test with a subset of models for faster execution.\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to the CSV data file\n",
    "        log_level: Logging level\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if test completed successfully\n",
    "    \"\"\"\n",
    "    logger = setup_logging(log_level)\n",
    "    logger.info(\"Running quick test with subset of models...\")\n",
    "    \n",
    "    # Use only fast models for quick testing\n",
    "    quick_models = ['DLinearModel', 'NLinearModel']\n",
    "    \n",
    "    # Temporarily reduce epochs for quick testing\n",
    "    original_epochs = CONFIG['epochs']\n",
    "    CONFIG['epochs'] = 10\n",
    "    \n",
    "    try:\n",
    "        success = run_full_pipeline(data_path, log_level, quick_models)\n",
    "        return success\n",
    "    finally:\n",
    "        # Restore original configuration\n",
    "        CONFIG['epochs'] = original_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1fda50",
   "metadata": {
    "vscode": {
     "languageId": "coffeescript"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main entry point with command line interface.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='DARTS Stock Forecasting System')\n",
    "    parser.add_argument('--data-path', '-d', \n",
    "                       default='Data/covariaterawdata1.csv',\n",
    "                       help='Path to CSV data file (default: Data/covariaterawdata1.csv)')\n",
    "    parser.add_argument('--log-level', '-l', \n",
    "                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],\n",
    "                       default='INFO',\n",
    "                       help='Logging level (default: INFO)')\n",
    "    parser.add_argument('--quick-test', '-q', \n",
    "                       action='store_true',\n",
    "                       help='Run quick test with subset of models')\n",
    "    parser.add_argument('--models-subset', '-m',\n",
    "                       nargs='+',\n",
    "                       help='Specific models to train (e.g., RNNModel TCNModel)')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    try:\n",
    "        if args.quick_test:\n",
    "            success = run_quick_test(args.data_path, args.log_level)\n",
    "        else:\n",
    "            success = run_full_pipeline(args.data_path, args.log_level, args.models_subset)\n",
    "        \n",
    "        sys.exit(0 if success else 1)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nPipeline interrupted by user\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6193e987",
   "metadata": {
    "vscode": {
     "languageId": "coffeescript"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
